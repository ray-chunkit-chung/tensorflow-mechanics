{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "introducing tensoflow functionality: graph, scope, summary, and checkpoints\n",
    "\n",
    "tensorflow v1.0.0 solving xor\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "        [0,0],\n",
    "        [0,1],\n",
    "        [1,0],\n",
    "        [1,1],\n",
    "    ])\n",
    "\n",
    "labels = np.array([\n",
    "        [0],\n",
    "        [1],\n",
    "        [1],\n",
    "        [0],\n",
    "    ])\n",
    "\n",
    "train_data = data\n",
    "train_labels = labels\n",
    "test_data = data\n",
    "test_labels = labels\n",
    "\n",
    "input_dim = data.shape[1]\n",
    "output_dim = labels.shape[1]\n",
    "hidden_dim = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from params import get_FLAGS\n",
    "\n",
    "FLAGS = get_FLAGS()\n",
    "# print(\"Parameters:\\n\")\n",
    "# for attr, value in sorted(FLAGS.__flags.items()):\n",
    "#     print(\"{}={}\".format(attr, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current step 1\n",
      "Iteration:  0\n",
      "予測: \n",
      "     [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "誤差=  0.77118\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\ray\\Dropbox\\github\\XOR-gate-tensorflow-mechanics\\runs\\2017-03-28T06.20.36.243445\\checkpoints\\model-1\n",
      "\n",
      "current step 101\n",
      "Iteration:  100\n",
      "予測: \n",
      "     [[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "誤差=  0.692562\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\ray\\Dropbox\\github\\XOR-gate-tensorflow-mechanics\\runs\\2017-03-28T06.20.36.243445\\checkpoints\\model-101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "\n",
    "    # ----------------------\n",
    "    # MLP\n",
    "    # ----------------------\n",
    "    with tf.device('/cpu:0'), tf.name_scope('mlp'):\n",
    "        x = tf.placeholder(tf.float32, [None, input_dim], name='input')\n",
    "        y_ = tf.placeholder(tf.float32, [None, output_dim],  name='label')\n",
    "\n",
    "        w1 = tf.Variable(tf.random_uniform([input_dim, hidden_dim], minval=-0.9, maxval=0.9), name='w1')\n",
    "        b1 = tf.Variable(tf.random_uniform([hidden_dim], minval=-0.9, maxval=0.9), name='b1')\n",
    "\n",
    "        hidden_layer = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "        w2 = tf.Variable(tf.random_uniform([hidden_dim, output_dim], minval=-0.9, maxval=0.9), name='w2')\n",
    "        b2 = tf.Variable(tf.random_uniform([output_dim], minval=-0.9, maxval=0.9), name='b2')\n",
    "\n",
    "        y = tf.sigmoid(tf.matmul(hidden_layer, w2) + b2)\n",
    "\n",
    "        \n",
    "    # ----------------------\n",
    "    # Training\n",
    "    # ----------------------\n",
    "    with tf.device('/gpu:0'), tf.name_scope('train'):\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        cross_entropy = tf.reduce_mean(- y_ * tf.log(y) - (1.0-y_) * tf.log(1.0-y), name=\"ce\")\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "        g_and_v = optimizer.compute_gradients(cross_entropy)\n",
    "        train_step = optimizer.apply_gradients(g_and_v, global_step=global_step)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(y), tf.round(y_))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "    \n",
    "    # ----------------------\n",
    "    # Session\n",
    "    # ----------------------\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    with sess.as_default():\n",
    "\n",
    "        # ----------------------\n",
    "        # Output folders\n",
    "        # ----------------------\n",
    "        time_str = datetime.datetime.now().isoformat().replace(\":\",\".\") #windows does not allow :\n",
    "        pwd = os.path.abspath(os.path.join(os.path.curdir))\n",
    "        out_dir = os.path.join(pwd, 'runs', time_str)\n",
    "        \n",
    "        # summary folders\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        \n",
    "        #\n",
    "        checkpoint_dir = os.path.join(out_dir, \"checkpoints\")\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        \n",
    "        # saver need an exisiting folder to save, but summary filewriter dont\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        \n",
    "        \n",
    "\n",
    "        # ----------------------\n",
    "        # Summaries\n",
    "        # ----------------------\n",
    "        loss_summary = tf.summary.scalar('loss', cross_entropy)\n",
    "        acc_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "        gradient_summary = []\n",
    "        for g, v in g_and_v:\n",
    "            if g is not None:\n",
    "                sparsity = tf.nn.zero_fraction(g)\n",
    "                g_hist_summary = tf.summary.histogram('{}/grad/hist'.format(v.name.replace(':','_')), g)\n",
    "                g_sparsity_summary = tf.summary.scalar('{}/grad/sparsity'.format(v.name.replace(':','_')), sparsity)\n",
    "                gradient_summary.append(g_hist_summary)\n",
    "                gradient_summary.append(g_sparsity_summary)\n",
    "        g_summary_merged = tf.summary.merge(gradient_summary)\n",
    "        \n",
    "        # Train Summaries\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, g_summary_merged])\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        # Dev summaries\n",
    "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "    \n",
    "    \n",
    "        # ----------------------\n",
    "        # Saver\n",
    "        # ----------------------\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "    \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for i in range(FLAGS.num_epochs + 1):\n",
    "            \n",
    "            feed_dict= {\n",
    "                x: train_data, y_: train_labels\n",
    "            }\n",
    "            _, ce, prediction = sess.run([train_step, cross_entropy, tf.round(y)], feed_dict=feed_dict)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            \n",
    "            if (i%100)==0:\n",
    "                print('current step', current_step)\n",
    "                print('Iteration: ', i)\n",
    "                print('予測: ')\n",
    "                print('    ', prediction)\n",
    "                print('誤差= ', ce)\n",
    "                print()\n",
    "                \n",
    "                feed_dict = {\n",
    "                  x: test_data,\n",
    "                  y_: test_labels\n",
    "                }\n",
    "                \n",
    "                step, d_summaries, t_summaries = sess.run(\n",
    "                    [global_step, dev_summary_op, train_summary_op],\n",
    "                    feed_dict=feed_dict\n",
    "                )\n",
    "                dev_summary_writer.add_summary(d_summaries, step)\n",
    "                train_summary_writer.add_summary(t_summaries, step)\n",
    "                \n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
